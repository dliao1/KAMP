---
title: "process_sim_results"
output:
  html_document: 
    toc: true
    toc_float: true
    code_folding: hide
hitheme: tomorrow
highlighter: highlight.js
date: "2026-02-11"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(message = FALSE)
```

```{r}
library(KAMP)
library(tidyverse)
library(spatstat.random)
library(microbenchmark)
library(spatstat.geom)
library(spatstat.explore)
library(ggplot2)
library(Rcpp)
library(kableExtra)
library(parallel)
library(here)
library(patchwork)
set.seed(50)
```

# TODOS
- Code profiling 
- Simulation studies
- Cleaning up code, comments
- Continued edits to vignettes, README, and function documentation
- Help files
- Edit unit tests


# Progress

## Larger simulation study:

- n = (500, 1000, 5000)
- Abundance = (0.1, 0.3)
- clust = (TRUE, FALSE)
- correction = (trans, iso)
- Bivariate inhomogenous
- reps = 100
- nperm = 1000
- Goal: compare K, Kinhom, KAMP, KAMP lite (thin_pct = 0.5), Kperm, KAMP variance, KAMP_lite variance, Kperm variance

### Analyses

- Computation time
- Degree of clustering 
- Variance: Power, Type 1 error 

### Results
- Successfully sped up KAMP by accepting a dataframe or a point process object in the main function :)

- Runtime 
  - KAMP and KAMP lite runtime were faster than K and much faster than Kperm, but was about 2x slower than Kinhom when n was larger
- Variance
  - Type 1 Error
    - Using correction = trans, KAMP type 1 error rate was pretty much the same as Kperm, while using correction = iso, KAMP type 1 error rate was lower than Kperm for smaller n and then higher than Kperm for larger n
  - Power
    - KAMP and Kperm had similar power, with KAMP_lite consistently having lower power (probably expected due to the thinning) 

# Questions + Next Steps
- Next Steps?



```{r}
sim_results <- list()
for (i in 1:23) {
  load(here("vignettes", "output_large", paste0(i, ".RDA")))
  sim_results[[i]] <- results_list
}

```

# Runtime

## Expectation
```{r}

runtime_summary <- data.frame()
for (i in 1:23) {
  scenario_times <- sim_results[[i]][[1]]$times
  median_times <- scenario_times %>%
    group_by(method) %>%
    summarize(median_elapsed = median(elapsed)) %>%
    mutate(
      n = sim_results[[i]][[1]]$times$n,
      abundance = sim_results[[i]][[1]]$times$abundance,
      clust = sim_results[[i]][[1]]$times$clust,
      correction = sim_results[[i]][[1]]$times$correction
    )
  
  runtime_summary <- rbind(runtime_summary, median_times)
}

runtime_summary_expectation <- runtime_summary %>% # now i want to select only method = K, KAMP, KAMP_lite, Kperm for expectation
  filter(method %in% c("K", "KAMP", "KAMP_lite", "Kinhom", "Kperm")) %>%
  select(n, abundance, clust, correction, method, median_elapsed)


ggplot(runtime_summary_expectation %>% filter(correction == "trans"), aes(x = factor(n), y = median_elapsed, fill = method)) +
  geom_boxplot(position = position_dodge(width = 0.85), width = 0.7) +
  facet_wrap(
    ~ clust,
    scales = "free_y",
    labeller = labeller(clust = c(
      "clust" = "With Clustering",
      "no_clust" = "No Clustering"
    ))
  ) +
  labs(
    title = "Runtime by Sample Size and Clustering (Translational Correction)",
    x = "Sample Size (n)",
    y = "Median Runtime (seconds, log10 scale)",
    fill = "Method"
  ) +
  scale_y_log10() +
  scale_x_discrete(expand = expansion(mult = c(0.15, 0.15))) +
  theme_minimal()

ggplot(runtime_summary_expectation %>% filter(correction == "iso"), aes(x = factor(n), y = median_elapsed, fill = method)) +
  geom_boxplot(position = position_dodge(width = 0.85), width = 0.7) +
  facet_wrap(
    ~ clust,
    scales = "free_y",
    labeller = labeller(clust = c(
      "clust" = "With Clustering",
      "no_clust" = "No Clustering"
    ))
  ) +
  labs(
    title = "Runtime by Sample Size and Clustering (Isotropic Correction)",
    x = "Sample Size (n)",
    y = "Median Runtime (seconds, log10 scale)",
    fill = "Method"
  ) +
  scale_y_log10() +
  scale_x_discrete(expand = expansion(mult = c(0.15, 0.15))) +
  theme_minimal()

```

```{r, results='asis'}
runtime_expectation_table <- runtime_summary_expectation %>%
  filter(correction == "trans") %>%
  group_by(n, method, clust) %>%
  summarise(median_runtime = median(median_elapsed), .groups = "drop") %>%
  pivot_wider(
    names_from = clust,
    values_from = median_runtime
  ) %>%
  arrange(n, method)

# splots into separate tables by n
tables_by_n <- split(runtime_expectation_table, runtime_expectation_table$n)

# print tables for each n, for correction=trans
for (n in names(tables_by_n)) {
  print(tables_by_n[[n]] %>%
          select(-n) %>%
          kable(format = "html", digits = 3, caption = paste("Median Runtime (seconds) for n =", n)) %>%
          kable_styling(full_width = FALSE, position = "center"))
  cat("\n\n")
}

```

## Variance
```{r}
runtime_summary_var <- runtime_summary %>% # now i want to select only method = KAMP_var, KAMP_lite_var, Kperm_var for variance
  filter(method %in% c("KAMP_var", "KAMP_lite_var", "Kperm_var")) %>%
  select(n, abundance, clust, correction, method, median_elapsed)


ggplot(runtime_summary_var  %>% filter(correction == "trans"), aes(x = factor(n), y = median_elapsed, fill = method)) +
  geom_boxplot(position = position_dodge(width = 0.85), width = 0.7) +
  facet_wrap(
    ~ clust,
    scales = "free_y",
    labeller = labeller(clust = c(
      "clust" = "With Clustering",
      "no_clust" = "No Clustering"
    ))
  ) +
  labs(
    title = "Runtime by Sample Size and Clustering (Translational Correction)",
    x = "Sample Size (n)",
    y = "Median Runtime (seconds, log10 scale)",
    fill = "Method"
  ) +
  scale_y_log10() +
  scale_x_discrete(expand = expansion(mult = c(0.15, 0.15))) +
  theme_minimal()

ggplot(runtime_summary_var %>% filter(correction == "iso"), aes(x = factor(n), y = median_elapsed, fill = method)) +
  geom_boxplot(position = position_dodge(width = 0.85), width = 0.7) +
  facet_wrap(
    ~ clust,
    scales = "free_y",
    labeller = labeller(clust = c(
      "clust" = "With Clustering",
      "no_clust" = "No Clustering"
    ))
  ) +
  labs(
    title = "Runtime by Sample Size and Clustering (Isotropic Correction)",
    x = "Sample Size (n)",
    y = "Median Runtime (seconds, log10 scale)",
    fill = "Method"
  ) +
  scale_y_log10() +
  scale_x_discrete(expand = expansion(mult = c(0.15, 0.15))) +
  theme_minimal()

```

```{r, results='asis'}
runtime_var_table <- runtime_summary_var %>%
  filter(correction == "trans") %>%
  group_by(n, method, clust) %>%
  summarise(median_runtime = median(median_elapsed), .groups = "drop") %>%
  pivot_wider(
    names_from = clust,
    values_from = median_runtime
  ) %>%
  arrange(n, method)

# splots into separate tables by n
tables_by_n <- split(runtime_var_table, runtime_var_table$n)

# print tables for each n, for correction=trans
for (n in names(tables_by_n)) {
  print(tables_by_n[[n]] %>%
          select(-n) %>%
          kable(format = "html", digits = 3, caption = paste("Median Runtime (seconds) for n =", n)) %>%
          kable_styling(full_width = FALSE, position = "center"))
  cat("\n\n")
}

```


# Degree of clustering


```{r}
r0 <- 0.15
doc_long <- data.frame()

for (i in seq_along(sim_results)) {
  for (j in seq_along(sim_results[[i]])) {

    res <- sim_results[[i]][[j]]

    k_val        <- res$results$k %>% filter(round(r, 2) == r0) %>% pull(fundiff)
    kinhom_val   <- res$results$kinhom  %>% filter(round(r, 2) == r0) %>% pull(fundiff)
    kperm_val    <- res$results$kperm   %>% filter(round(r, 2) == r0) %>% pull(fundiff)
    kamp_val     <- res$results$kamp    %>% filter (round(r, 2) == r0) %>% pull(kamp)
    kamp_lite_val<- res$results$kamp_lite %>% filter(round(r, 2) == r0) %>% pull(kamp)
    kamp_var_val <- res$results$kamp_var %>% filter(round(r, 2) == r0) %>% pull(kamp)
    kamp_lite_var_val <- res$results$kamp_lite_var %>% filter(round(r, 2) == r0) %>% pull(kamp)
    kperm_var_val <- res$results$kperm_var %>% filter(method == "perm") %>% filter(round(r, 2) == r0) %>% pull(fundiff)

    tmp <- data.frame(
      scenario = i,
      run = j,
      r = r0,
      n = unique(res$times$n)[1],
      clust = unique(res$times$clust)[1],
      abundance = unique(res$times$abundance)[1],
      correction = unique(res$times$correction)[1],
      method = c("K", "Kinhom", "Kperm", "KAMP", "KAMP_lite", "KAMP_var", "KAMP_lite_var", "Kperm_var"),
      doc = c(k_val, kinhom_val, kperm_val, kamp_val, kamp_lite_val, kamp_var_val, kamp_lite_var_val, kperm_var_val)
    )
    

    doc_long <- rbind(doc_long, tmp)
  }
}

```


```{r}

clustering_df <- doc_long %>% filter(method %in% c("K", "KAMP", "KAMP_lite", "Kinhom", "Kperm"))

p1 <- ggplot(subset(clustering_df, clust == FALSE),
             aes(x = factor(n), y = doc, fill = method)) +
  geom_hline(yintercept = 0, linewidth = 0.4) +
  geom_boxplot(width = 0.85, size = 1, outlier.shape = NA,
               position = position_dodge(0.9)) +
  coord_cartesian(ylim = c(-0.025, 0.1)) +
  labs(
    title = "clust = FALSE",
    x = "Sample Size (n)",
    y = "Degree of clustering",
    fill = "Method"
  ) +
  theme_minimal(base_size = 14)

p2 <- ggplot(subset(clustering_df, clust == TRUE),
             aes(x = factor(n), y = doc, fill = method)) +
  geom_hline(yintercept = 0, linewidth = 0.4) +
  geom_boxplot(width = 0.85, size = 1, outlier.shape = NA,
               position = position_dodge(0.9)) +
  coord_cartesian(ylim = c(-0.1, 0.3)) +
  labs(
    title = "clust = TRUE",
    x = "Sample Size (n)",
    y = "Degree of clustering",
    fill = "Method"
  ) +
  theme_minimal(base_size = 14)

p1 

p2

```

# Variance
```{r}
r0 <- 0.25
alpha <- 0.05

get_p_at_r0 <- function(df, r0) {
  if (is.null(df) || nrow(df) == 0) return(NA_real_)
  df %>%
    mutate(dist = abs(r - r0)) %>%
    arrange(dist) %>%
    slice(1) %>%
    pull(pvalue)
}

p_long <- imap_dfr(sim_results, function(scn, i) {
  imap_dfr(scn, function(res, j) {
    tibble(
      scenario   = i,
      run        = j,
      n          = unique(res$times$n)[1],
      abundance  = unique(res$times$abundance)[1],
      clust      = unique(res$times$clust)[1],
      correction = unique(res$times$correction)[1],
      
      # use kperm method = "kperm approx"
      Kperm      = get_p_at_r0(res$results$kperm_var %>% filter(method == "kperm approx"), r0),
      KAMP       = get_p_at_r0(res$results$kamp_var, r0),
      KAMP_lite  = get_p_at_r0(res$results$kamp_lite_var, r0)
    ) %>%
      pivot_longer(c(Kperm, KAMP, KAMP_lite),
                   names_to = "method",
                   values_to = "pvalue") %>%
      mutate(reject = if_else(!is.na(pvalue) & pvalue <= alpha, 1L, 0L))
  })
})

type1_df <- p_long %>%
  filter(clust == FALSE) %>%
  group_by(n, abundance, correction, method) %>%
  summarise(
    n_eff = sum(!is.na(pvalue)),  #effective sample size
    type1_error = mean(reject[!is.na(pvalue)]),
    .groups = "drop"
  )

power_df <- p_long %>%
  filter(clust == TRUE) %>%
  group_by(n, abundance, correction, method) %>%
  summarise(power = mean(reject, na.rm = TRUE), .groups = "drop")

ggplot(type1_df, aes(x = factor(n), y = type1_error, color = method)) +
  geom_hline(yintercept = alpha, linetype = "dashed") +
  geom_point(size = 2, position = position_dodge(width = 0.4)) +
  facet_grid(correction ~ abundance) +
  labs(
    title = "Type I error = P(reject H0 | H0 true)",
    x = "Sample size (n)",
    y = "type1_error"
  ) +
  theme_minimal()

ggplot(power_df, aes(x = factor(n), y = power, color = method)) +
  geom_hline(yintercept = alpha, linetype = "dashed") +
  geom_point(size = 2, position = position_dodge(width = 0.4)) +
  facet_grid(correction ~ abundance) +
  labs(
    title = "Power = P(reject H0 | H1 true)",
    x = "Sample size (n)",
    y = "power"
  ) +
  theme_minimal()
```



